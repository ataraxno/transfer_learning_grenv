{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Metric\n",
    "class RSquare(Metric):\n",
    "    \"\"\"Compute R^2 score.\n",
    "     This is also called as coefficient of determination.\n",
    "     It tells how close are data to the fitted regression line.\n",
    "     - Highest score can be 1.0 and it indicates that the predictors\n",
    "       perfectly accounts for variation in the target.\n",
    "     - Score 0.0 indicates that the predictors do not\n",
    "       account for variation in the target.\n",
    "     - It can also be negative if the model is worse.\n",
    "     Usage:\n",
    "     ```python\n",
    "     actuals = tf.constant([1, 4, 3], dtype=tf.float32)\n",
    "     preds = tf.constant([2, 4, 4], dtype=tf.float32)\n",
    "     result = tf.keras.metrics.RSquare()\n",
    "     result.update_state(actuals, preds)\n",
    "     print('R^2 score is: ', r1.result().numpy()) # 0.57142866\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name='r_square', dtype=tf.float32):\n",
    "        super(RSquare, self).__init__(name=name, dtype=dtype)\n",
    "        self.squared_sum = self.add_weight(\"squared_sum\", initializer=\"zeros\")\n",
    "        self.sum = self.add_weight(\"sum\", initializer=\"zeros\")\n",
    "        self.res = self.add_weight(\"residual\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred):\n",
    "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
    "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
    "        self.squared_sum.assign_add(tf.reduce_sum(y_true**2))\n",
    "        self.sum.assign_add(tf.reduce_sum(y_true))\n",
    "        self.res.assign_add(\n",
    "            tf.reduce_sum(tf.square(tf.subtract(y_true, y_pred))))\n",
    "        self.count.assign_add(tf.cast(tf.shape(y_true)[0], tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        mean = self.sum / self.count\n",
    "        total = self.squared_sum - 2 * self.sum * mean + self.count * mean**2\n",
    "        return 1 - (self.res / total)\n",
    "\n",
    "    def reset_states(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.squared_sum.assign(0.0)\n",
    "        self.sum.assign(0.0)\n",
    "        self.res.assign(0.0)\n",
    "        self.count.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import (LinearLocator, MultipleLocator, FormatStrFormatter)\n",
    "from matplotlib.dates import MONDAY\n",
    "from matplotlib.dates import MonthLocator, WeekdayLocator, DateFormatter\n",
    "from matplotlib import gridspec\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = ((8/2.54), (6/2.54))\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"mathtext.default\"] = \"rm\"\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "MARKER_SIZE = 15\n",
    "cmap_m = [\"#f4a6ad\", \"#f6957e\", \"#fccfa2\", \"#8de7be\", \"#86d6f2\", \"#24a9e4\", \"#b586e0\", \"#d7f293\"]\n",
    "cmap = [\"#e94d5b\", \"#ef4d28\", \"#f9a54f\", \"#25b575\", \"#1bb1e7\", \"#1477a2\", \"#a662e5\", \"#c2f442\"]\n",
    "\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "# plt.rcParams['axes.edgecolor'] = \n",
    "plt.rcParams['axes.linewidth'] = 1\n",
    "plt.rcParams['lines.linewidth'] = 1.5\n",
    "plt.rcParams['xtick.major.width'] = 1\n",
    "plt.rcParams['xtick.minor.width'] = 1\n",
    "plt.rcParams['ytick.major.width'] = 1\n",
    "plt.rcParams['ytick.minor.width'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_patch_spines_invisible(ax):\n",
    "    ax.set_frame_on(True)\n",
    "    ax.patch.set_visible(False)\n",
    "    for sp in ax.spines.values():\n",
    "        sp.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.load('./env_set/dataset.npz')\n",
    "train_input = l['train_input']\n",
    "train_label = l['train_label']\n",
    "test_input = l['test_input']\n",
    "test_label = l['test_label']\n",
    "MAXS = l['MAXS']\n",
    "MINS = l['MINS']\n",
    "\n",
    "TIME_STEPS = l['TIME_STEPS']\n",
    "OUTPUT_SIZE = l['OUTPUT_SIZE']\n",
    "NUM_FEATURES = train_input.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41025, 24, 5)\n",
      "(41025, 24, 5)\n",
      "\n",
      "(16119, 24, 5)\n",
      "(16119, 24, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape)\n",
    "print(train_label.shape)\n",
    "print()\n",
    "print(test_input.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = np.concatenate([train_input, train_label], axis=0).astype(np.float32)\n",
    "testset = np.concatenate([test_input, test_label], axis=0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((trainset, trainset))\n",
    "train_dataset = train_dataset.cache().shuffle(BATCH_SIZE*100).batch(BATCH_SIZE).repeat()\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((testset, testset))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrainLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_hidden, activation=tf.nn.relu):\n",
    "        super(RetrainLayer, self).__init__()\n",
    "        self.num_hidden = num_hidden\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(self.num_hidden, activation=activation, kernel_initializer='he_uniform')\n",
    "        \n",
    "    def call(self, inp):\n",
    "        return self.dense(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_hiddens, encoding_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.encoding_size = encoding_size\n",
    "        \n",
    "        self.denses = [tf.keras.layers.Dense(self.num_hiddens[_], activation=tf.nn.relu, kernel_initializer='he_uniform')\n",
    "                       for _ in range(len(self.num_hiddens))]\n",
    "        \n",
    "        self.output_layer = tf.keras.layers.Dense(self.encoding_size, activation=tf.nn.sigmoid)\n",
    "        \n",
    "    def call(self, inp):\n",
    "        for _ in range(len(self.num_hiddens)):\n",
    "            inp = self.denses[_](inp)\n",
    "        \n",
    "        return self.output_layer(inp)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_hiddens, original_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.num_hiddens = num_hiddens[::-1]\n",
    "        self.original_size = original_size\n",
    "        \n",
    "        self.denses = [tf.keras.layers.Dense(self.num_hiddens[_], activation=tf.nn.relu, kernel_initializer='he_uniform')\n",
    "                       for _ in range(len(self.num_hiddens))]\n",
    "        \n",
    "    def call(self, inp):\n",
    "        for _ in range(len(self.num_hiddens)):\n",
    "            inp = self.denses[_](inp)\n",
    "        \n",
    "        return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, num_hiddens, encoding_size, original_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.encoding_size = encoding_size\n",
    "        self.original_size = original_size\n",
    "        \n",
    "        self.in_retrain_layer = RetrainLayer(self.num_hiddens[0])\n",
    "        self.encoder = Encoder(self.num_hiddens, self.encoding_size)\n",
    "        self.decoder = Decoder(self.num_hiddens, self.original_size)\n",
    "        self.out_retrain_layer = RetrainLayer(self.original_size, activation = tf.nn.sigmoid)\n",
    "        \n",
    "    def call(self, inp, need_code=False, decoding=None):\n",
    "        inp = self.in_retrain_layer(inp)\n",
    "        encoded_values = self.encoder(inp)\n",
    "        if decoding is not None:\n",
    "            decoding = self.decoder(decoding)\n",
    "            return self.out_retrain_layer(decoding)\n",
    "        if not need_code:\n",
    "            encoded_values = self.decoder(encoded_values)\n",
    "            return self.out_retrain_layer(encoded_values)\n",
    "        else:\n",
    "            return encoded_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, original):\n",
    "    reconstruction_error = tf.reduce_mean(tf.square(tf.subtract(model(original), original)))\n",
    "    return reconstruction_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train(loss, model, opt, original):\n",
    "    with tf.GradientTape() as tape:\n",
    "        gradients = tape.gradient(loss(model, original), model.trainable_variables)\n",
    "        gradient_variables = zip(gradients, model.trainable_variables)\n",
    "        opt.apply_gradients(gradient_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens = [32, 16]\n",
    "encoding_size = 8\n",
    "original_size = 5\n",
    "autoencoder = Autoencoder(num_hiddens, encoding_size, original_size)\n",
    "opt = tf.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/trained_AE\"\n",
    "ckpt = tf.train.Checkpoint(autoencoder=autoencoder,\n",
    "                           opt=opt)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.create_file_writer('tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-59\n",
      "Epoch 0 batch 0 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-60\n",
      "Epoch 0 batch 500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-61\n",
      "Epoch 0 batch 1000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-62\n",
      "Epoch 0 batch 1500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 2000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-63\n",
      "Epoch 0 batch 2500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 3000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 3500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 4000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 4500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 5000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 5500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 6000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 6500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 7000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 7500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 8000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 8500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 9000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 9500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 10000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 10500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 11000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-64\n",
      "Epoch 0 batch 11500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-65\n",
      "Epoch 0 batch 12000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 12500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 13000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 13500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 14000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 14500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 15000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 15500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 16000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-66\n",
      "Epoch 0 batch 16500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 17000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 17500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 18000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 18500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 19000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 19500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 20000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 20500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 21000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 21500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 22000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 22500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 23000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 23500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 24000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 24500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 25000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 25500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 26000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 26500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 27000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 27500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 28000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 28500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 29000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 29500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-67\n",
      "Epoch 0 batch 30000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 30500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 31000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 31500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 32000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 32500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 33000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 33500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 34000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-68\n",
      "Epoch 0 batch 34500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 35000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 35500 train loss: 0.0000 test loss: 0.0002\n",
      "Epoch 0 batch 36000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 36500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 37000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 37500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 38000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 38500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 39000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 39500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 40000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 40500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-69\n",
      "Epoch 0 batch 41000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 41500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 42000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 42500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 43000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 43500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 44000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 44500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 45000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 45500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 46000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 46500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 47000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 47500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 48000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 48500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 49000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 49500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 50000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 50500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 51000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 51500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 52000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 52500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 53000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 53500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 54000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 54500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 55000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 55500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 56000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 56500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 57000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 57500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 58000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 58500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 59000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 59500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 60000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 60500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 61000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 61500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 62000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 62500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 63000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 63500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 64000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 64500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 65000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-70\n",
      "Epoch 0 batch 65500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 66000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 66500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 67000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 67500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 68000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 68500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 69000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 69500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 70000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-71\n",
      "Epoch 0 batch 70500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 71000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 71500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 72000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 72500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 73000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 73500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 74000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 74500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 75000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 75500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 76000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 76500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 77000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 77500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 78000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 78500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 79000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 79500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 80000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 80500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 81000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 81500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 82000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 82500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 83000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 83500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 84000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 84500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 85000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 85500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 86000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 86500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 87000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 87500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 88000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 88500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 89000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 89500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 90000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 90500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 91000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 91500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 92000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 92500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 93000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 93500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 94000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 94500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 95000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 95500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 96000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 96500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 97000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 97500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 98000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 98500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 99000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 99500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 100000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 100500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 101000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 101500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 102000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 102500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 103000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 103500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 104000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 104500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 105000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 105500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 106000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 106500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 107000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 107500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 108000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 108500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-72\n",
      "Epoch 0 batch 109000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 109500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 110000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 110500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 111000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 111500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 112000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 112500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 113000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 113500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 114000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 114500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 115000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 115500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 116000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 116500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 117000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 117500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 118000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 118500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 119000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 119500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 120000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 120500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 121000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 121500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 122000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 122500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 123000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 123500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 124000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 124500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 125000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 125500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 126000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 126500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 127000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 127500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 128000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 128500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 129000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 129500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 130000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 130500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 131000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 131500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 132000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 132500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 133000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 133500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 134000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 134500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 135000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 135500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 136000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 136500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 137000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 137500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 138000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 138500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 139000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 139500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 140000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 140500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 141000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 141500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 142000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 142500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 143000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 143500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 144000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 144500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 145000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 145500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 146000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 146500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 147000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-73\n",
      "Epoch 0 batch 147500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 148000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 148500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 149000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 149500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 150000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 150500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 151000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 151500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 152000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 152500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 153000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 153500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 154000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 154500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 155000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 155500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 156000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 156500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 157000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 157500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 158000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 158500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 159000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 159500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 160000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 160500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 161000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 161500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 162000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 162500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 163000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 163500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 164000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 164500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 165000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 165500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 166000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 166500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 167000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 167500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 168000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 168500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 169000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 169500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 170000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 170500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 171000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 171500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 172000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 172500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 173000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 173500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 174000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 174500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 175000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 175500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 176000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 176500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 177000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 177500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 178000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 178500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 179000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-74\n",
      "Epoch 0 batch 179500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 180000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 180500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 181000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 181500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 182000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 182500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 183000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 183500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 184000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-75\n",
      "Epoch 0 batch 184500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 185000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 185500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 186000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 186500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 187000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 187500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 188000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 188500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 189000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 189500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 190000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 190500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 191000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 191500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 192000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-76\n",
      "Epoch 0 batch 192500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 193000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 193500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 194000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 194500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 195000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 195500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 196000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 196500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 197000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-77\n",
      "Epoch 0 batch 197500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 198000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 198500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 199000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 199500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-78\n",
      "Epoch 0 batch 200000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 200500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 201000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 201500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 202000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 202500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 203000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 203500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 204000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 204500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 205000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 205500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 206000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 206500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 207000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 207500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 208000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 208500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 209000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 209500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 210000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 210500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 211000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 211500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 212000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 212500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 213000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 213500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 214000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 214500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 215000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 215500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 216000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 216500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 217000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 217500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 218000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 218500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 219000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 219500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 220000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-79\n",
      "Epoch 0 batch 220500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 221000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 221500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 222000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 222500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 223000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 223500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 224000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 224500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 225000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 225500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 226000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 226500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 227000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 227500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 228000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 228500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 229000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 229500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 230000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 230500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 231000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 231500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-80\n",
      "Epoch 0 batch 232000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 232500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 233000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 233500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 234000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 234500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 235000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 235500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-81\n",
      "Epoch 0 batch 236000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 236500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 237000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 237500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 238000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-82\n",
      "Epoch 0 batch 238500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 239000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 239500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 240000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 240500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 241000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 241500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 242000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 242500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 243000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 243500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 244000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 244500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-83\n",
      "Epoch 0 batch 245000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 245500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 246000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 246500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 247000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-84\n",
      "Epoch 0 batch 247500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 248000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 248500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 249000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 249500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 250000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 250500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 251000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 251500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 252000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 252500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 253000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 253500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 254000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 254500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 255000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 255500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 256000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 256500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 257000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 257500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 258000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 258500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 259000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 259500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 260000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 260500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 261000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 261500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 262000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 262500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 263000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 263500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 264000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 264500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 265000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-85\n",
      "Epoch 0 batch 265500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 266000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 266500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 267000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 267500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 268000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 268500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 269000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 269500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 270000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 270500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 271000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 271500 train loss: 0.0000 test loss: 0.0002\n",
      "Epoch 0 batch 272000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 272500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 273000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 273500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 274000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 274500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 275000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 275500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 276000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 276500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 277000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 277500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 278000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 278500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 279000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 279500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 280000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 280500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 281000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 281500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 282000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 282500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 283000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 283500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 284000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 284500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 285000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 285500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 286000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 286500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 287000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 287500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 288000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 288500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 289000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 289500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 290000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 290500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 291000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 291500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 292000 train loss: 0.0000 test loss: 0.0002\n",
      "Epoch 0 batch 292500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 293000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 293500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 294000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 294500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 295000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 295500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 296000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 296500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 297000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 297500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 298000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 298500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 299000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 299500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 300000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 300500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 301000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 301500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 302000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 302500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 303000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 303500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 304000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 304500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 305000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 305500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 306000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 306500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 307000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 307500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 308000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 308500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 309000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 309500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 310000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 310500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 311000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 311500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 312000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 312500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 313000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 313500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 314000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 314500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 315000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 315500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 316000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 316500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 317000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 317500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 318000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 318500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 319000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 319500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 320000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 320500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 321000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 321500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 322000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 322500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 323000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 323500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 324000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 324500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 325000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 325500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 326000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 326500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 327000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 327500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 328000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 328500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 329000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 329500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 330000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 330500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 331000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 331500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 332000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 332500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 333000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 333500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 334000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 334500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 335000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 335500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 336000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 336500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 337000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 337500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 338000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 338500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 339000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 339500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 340000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 340500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 341000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 341500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 342000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 342500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 343000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 343500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 344000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 344500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 345000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 345500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 346000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 346500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 347000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 347500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 348000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 348500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 349000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 349500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 350000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 350500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 351000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 351500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 352000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 352500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 353000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 353500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 354000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 354500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 355000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 355500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 356000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 356500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 357000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 357500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 358000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 358500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 359000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 359500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 360000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 360500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 361000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 361500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 362000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 362500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 363000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 363500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 364000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 364500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 365000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 365500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 366000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 366500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 367000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 367500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-86\n",
      "Epoch 0 batch 368000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 368500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 369000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 369500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 370000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 370500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 371000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 371500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 372000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 372500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 373000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 373500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 374000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 374500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 375000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 375500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 376000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 376500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 377000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 377500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 378000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 378500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 379000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 379500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 380000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 380500 train loss: 0.0001 test loss: 0.0004\n",
      "Epoch 0 batch 381000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 381500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 382000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 382500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 383000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 383500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 384000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 384500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 385000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 385500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-87\n",
      "Epoch 0 batch 386000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 386500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 387000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 387500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 388000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 388500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 389000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 389500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 390000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 390500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 391000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 391500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 392000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 392500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 393000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 393500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 394000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 394500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 395000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 395500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 396000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 396500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 397000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 397500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 398000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 398500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 399000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 399500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 400000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 400500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 401000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 401500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 402000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 402500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 403000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 403500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-88\n",
      "Epoch 0 batch 404000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 404500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 405000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 405500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 406000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 406500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 407000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 407500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 408000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 408500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 409000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 409500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 410000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 410500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 411000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 411500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 412000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 412500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 413000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 413500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 414000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 414500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 415000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 415500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 416000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 416500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 417000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 417500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 418000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 418500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 419000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 419500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 420000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 420500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 421000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 421500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 422000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 422500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 423000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 423500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 424000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 424500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 425000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 425500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 426000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 426500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 427000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 427500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 428000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 428500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 429000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 429500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 430000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 430500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 431000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 431500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 432000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 432500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 433000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 433500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 434000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 434500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 435000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 435500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 436000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 436500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 437000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 437500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 438000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 438500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 439000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 439500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 440000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 440500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 441000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 441500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 442000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 442500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 443000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 443500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 444000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 444500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 445000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 445500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 446000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 446500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 447000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 447500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 448000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 448500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 449000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 449500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 450000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 450500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 451000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 451500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 452000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 452500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 453000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 453500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 454000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 454500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 455000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 455500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 456000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 456500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 457000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 457500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 458000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 458500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 459000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 459500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 460000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 460500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 461000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 461500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 462000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 462500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 463000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 463500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 464000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 464500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 465000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 465500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 466000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 466500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 467000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 467500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 468000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 468500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 469000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 469500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 470000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 470500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 471000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 471500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 472000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 472500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 473000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 473500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 474000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 474500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 475000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 475500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 476000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 476500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 477000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 477500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 478000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 478500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 479000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 479500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 480000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 480500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 481000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 481500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 482000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 482500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 483000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 483500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 484000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 484500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 485000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 485500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 486000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 486500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 487000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 487500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 488000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 488500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 489000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 489500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 490000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 490500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 491000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 491500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 492000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 492500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 493000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 493500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 494000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 494500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 495000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 495500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 496000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 496500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 497000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 497500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 498000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 498500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 499000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 499500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 500000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 500500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 501000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 501500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 502000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 502500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 503000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 503500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 504000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 504500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 505000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 505500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 506000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 506500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 507000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 507500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 508000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 508500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 509000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 509500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 510000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 510500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 511000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 511500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 512000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 512500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 513000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 513500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 514000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 514500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 515000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 515500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 516000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 516500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 517000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 517500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 518000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 518500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 519000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 519500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 520000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 520500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 521000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 521500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 522000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 522500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 523000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 523500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 524000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 524500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 525000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 525500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 526000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 526500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 527000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 527500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 528000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 528500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 529000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 529500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 530000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 530500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 531000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 531500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 532000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 532500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 533000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 533500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 534000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 534500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 535000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 535500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 536000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 536500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 537000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 537500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 538000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 538500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 539000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 539500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 540000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 540500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 541000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 541500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 542000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-89\n",
      "Epoch 0 batch 542500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 543000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 543500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 544000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 544500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 545000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 545500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 546000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 546500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 547000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-90\n",
      "Epoch 0 batch 547500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 548000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 548500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 549000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 549500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 550000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 550500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 551000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 551500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 552000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 552500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 553000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 553500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 554000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 554500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 555000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 555500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 556000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 556500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 557000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 557500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 558000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 558500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 559000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 559500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 560000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 560500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 561000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 561500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 562000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 562500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 563000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 563500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 564000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 564500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 565000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 565500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 566000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 566500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 567000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 567500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 568000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 568500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 569000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 569500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 570000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 570500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 571000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 571500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 572000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 572500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 573000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 573500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 574000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 574500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 575000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 575500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 576000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 576500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 577000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 577500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 578000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 578500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 579000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 579500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 580000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 580500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 581000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 581500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 582000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 582500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 583000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 583500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 584000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 584500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 585000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 585500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 586000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 586500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 587000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 587500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 588000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 588500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 589000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 589500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 590000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 590500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 591000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 591500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 592000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 592500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 593000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 593500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 594000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 594500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 595000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 595500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 596000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-91\n",
      "Epoch 0 batch 596500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 597000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 597500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 598000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 598500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 599000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 599500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 600000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 600500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 601000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 601500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 602000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 602500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 603000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 603500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 604000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 604500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 605000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 605500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 606000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 606500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 607000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 607500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 608000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 608500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 609000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 609500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 610000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 610500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 611000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 611500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 612000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 612500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 613000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 613500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 614000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 614500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 615000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 615500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 616000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 616500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 617000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 617500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 618000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-92\n",
      "Epoch 0 batch 618500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 619000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 619500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 620000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 620500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 621000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 621500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 622000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 622500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 623000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 623500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 624000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 624500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-93\n",
      "Epoch 0 batch 625000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 625500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 626000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 626500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 627000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 627500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 628000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 628500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 629000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 629500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 630000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 630500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 631000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 631500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 632000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 632500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 633000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 633500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 634000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 634500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 635000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 635500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 636000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 636500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 637000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 637500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 638000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 638500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 639000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 639500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 640000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 640500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 641000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 641500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 642000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 642500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 643000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 643500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 644000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 644500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 645000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 645500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 646000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 646500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 647000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 647500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 648000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 648500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 649000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 649500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 650000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 650500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 651000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 651500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 652000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 652500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 653000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 653500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 654000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 654500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 655000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 655500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 656000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 656500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 657000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 657500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 658000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 658500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 659000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 659500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 660000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 660500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 661000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 661500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 662000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 662500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 663000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 663500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 664000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 664500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 665000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 665500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 666000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 666500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 667000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 667500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 668000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 668500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 669000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 669500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 670000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 670500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 671000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 671500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 672000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 672500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 673000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 673500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 674000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 674500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 675000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 675500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 676000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 676500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 677000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 677500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 678000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 678500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 679000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 679500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 680000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 680500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 681000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 681500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 682000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 682500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 683000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 683500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 684000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 684500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 685000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 685500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 686000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 686500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 687000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 687500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 688000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 688500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 689000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 689500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 690000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 690500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 691000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 691500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 692000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 692500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 693000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 693500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 694000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 694500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 695000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 695500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 696000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 696500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 697000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 697500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 698000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 698500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 699000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 699500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 700000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 700500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 701000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 701500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 702000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 702500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 703000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 703500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 704000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 704500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 705000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 705500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 706000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 706500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 707000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 707500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 708000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 708500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 709000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 709500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 710000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 710500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 711000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 711500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 712000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 712500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 713000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 713500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 714000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-94\n",
      "Epoch 0 batch 714500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 715000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 715500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 716000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 716500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 717000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 717500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 718000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 718500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 719000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 719500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 720000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 720500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 721000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 721500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 722000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 722500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 723000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 723500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 724000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 724500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 725000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 725500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 726000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 726500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 727000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 727500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 728000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 728500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 729000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 729500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 730000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 730500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 731000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 731500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 732000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 732500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 733000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 733500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 734000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 734500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 735000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 735500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 736000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 736500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 737000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 737500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 738000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 738500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 739000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 739500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 740000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 740500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 741000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 741500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 742000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 742500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 743000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 743500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 744000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 744500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 745000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 745500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 746000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 746500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 747000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 747500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 748000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 748500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 749000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 749500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 750000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 750500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 751000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 751500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 752000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 752500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 753000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 753500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 754000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 754500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 755000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-95\n",
      "Epoch 0 batch 755500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 756000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 756500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 757000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 757500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 758000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 758500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 759000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 759500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 760000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 760500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 761000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 761500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 762000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 762500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 763000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 763500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 764000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 764500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 765000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 765500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 766000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 766500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 767000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 767500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 768000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 768500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 769000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 769500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 770000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 770500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 771000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 771500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 772000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 772500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 773000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 773500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 774000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-96\n",
      "Epoch 0 batch 774500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 775000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 775500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 776000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 776500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 777000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 777500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 778000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 778500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 779000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 779500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 780000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 780500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 781000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 781500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 782000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 782500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 783000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 783500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 784000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 784500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 785000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 785500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 786000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 786500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 787000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 787500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 788000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 788500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 789000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 789500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 790000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 790500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 791000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 791500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 792000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 792500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 793000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 793500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 794000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 794500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 795000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 795500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 796000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 796500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 797000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 797500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 798000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 798500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 799000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 799500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 800000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 800500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 801000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 801500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 802000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 802500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 803000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 803500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 804000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 804500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 805000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 805500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 806000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 806500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 807000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 807500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 808000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 808500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 809000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 809500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 810000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 810500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 811000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 811500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 812000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 812500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 813000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 813500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 814000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 814500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 815000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 815500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 816000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 816500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 817000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 817500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 818000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 818500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 819000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 819500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 820000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 820500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 821000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 821500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 822000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 822500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 823000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 823500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 824000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 824500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 825000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 825500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 826000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 826500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 827000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 827500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 828000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 828500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 829000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 829500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-97\n",
      "Epoch 0 batch 830000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 830500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 831000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 831500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 832000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 832500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 833000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 833500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 834000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 834500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 835000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 835500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 836000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 836500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 837000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 837500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 838000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 838500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 839000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 839500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 840000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 840500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 841000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 841500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 842000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 842500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 843000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 843500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 844000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 844500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 845000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 845500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 846000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 846500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 847000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 847500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 848000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 848500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 849000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 849500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 850000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 850500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 851000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 851500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 852000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 852500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 853000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 853500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 854000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 854500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 855000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 855500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 856000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 856500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 857000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 857500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 858000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 858500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 859000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 859500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 860000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 860500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 861000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 861500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 862000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 862500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 863000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 863500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 864000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 864500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 865000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 865500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 866000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 866500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 867000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 867500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 868000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 868500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 869000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 869500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 870000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 870500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 871000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 871500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 872000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 872500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 873000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 873500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 874000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 874500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 875000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 875500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 876000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 876500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 877000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 877500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 878000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 878500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 879000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 879500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 880000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 880500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 881000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 881500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 882000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 882500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 883000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 883500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 884000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 884500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 885000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 885500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 886000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 886500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 887000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 887500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 888000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 888500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 889000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 889500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 890000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 890500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 891000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 891500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 892000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 892500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 893000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 893500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 894000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 894500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 895000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 895500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 896000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-98\n",
      "Epoch 0 batch 896500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 897000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-99\n",
      "Epoch 0 batch 897500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 898000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 898500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-100\n",
      "Epoch 0 batch 899000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 899500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 900000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 900500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 901000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 901500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 902000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 902500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 903000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 903500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 904000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 904500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 905000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 905500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 906000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 906500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 907000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 907500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 908000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 908500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 909000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 909500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 910000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 910500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 911000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 911500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 912000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 912500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 913000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 913500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 914000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 914500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 915000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 915500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 916000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 916500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 917000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 917500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 918000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 918500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 919000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 919500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 920000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 920500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 921000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 921500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 922000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 922500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 923000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 923500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 924000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 924500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 925000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 925500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 926000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 926500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 927000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 927500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 928000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 928500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 929000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 929500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 930000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 930500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 931000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 931500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 932000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 932500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 933000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 933500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 934000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 934500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 935000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 935500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-101\n",
      "Epoch 0 batch 936000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 936500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 937000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 937500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 938000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 938500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 939000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 939500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 940000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 940500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 941000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 941500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 942000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 942500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 943000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 943500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-102\n",
      "Epoch 0 batch 944000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 944500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-103\n",
      "Epoch 0 batch 945000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 945500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 946000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 946500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 947000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 947500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 948000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 948500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 949000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 949500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 950000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 950500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 951000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 951500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 952000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 952500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 953000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 953500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 954000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 954500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 955000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 955500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 956000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 956500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 957000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 957500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 958000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 958500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 959000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 959500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 960000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 960500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-104\n",
      "Epoch 0 batch 961000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 961500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 962000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 962500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 963000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 963500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 964000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 964500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 965000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 965500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 966000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 966500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 967000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 967500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 968000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 968500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 969000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 969500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 970000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 970500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 971000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 971500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-105\n",
      "Epoch 0 batch 972000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 972500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 973000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 973500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 974000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 974500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 975000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 975500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 976000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 976500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 977000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 977500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 978000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 978500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-106\n",
      "Epoch 0 batch 979000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 979500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 980000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 980500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 981000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 981500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 982000 train loss: 0.0000 test loss: 0.0002\n",
      "Epoch 0 batch 982500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 983000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 983500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 984000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 984500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 985000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 985500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 986000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 986500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 987000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 987500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 988000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 988500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 989000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 989500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 990000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 990500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 991000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 991500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 992000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 992500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 993000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 993500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 994000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 994500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 995000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 995500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 996000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-107\n",
      "Epoch 0 batch 996500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 997000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 997500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 998000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 998500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 999000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 999500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1000000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1000500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1001000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1001500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1002000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1002500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1003000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1003500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1004000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1004500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1005000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1005500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1006000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1006500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1007000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1007500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1008000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1008500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1009000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1009500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1010000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1010500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1011000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1011500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1012000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1012500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1013000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1013500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1014000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-108\n",
      "Epoch 0 batch 1014500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1015000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1015500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1016000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1016500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-109\n",
      "Epoch 0 batch 1017000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1017500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1018000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1018500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1019000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1019500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1020000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1020500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1021000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1021500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1022000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1022500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1023000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1023500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1024000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1024500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1025000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1025500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1026000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1026500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1027000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1027500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1028000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-110\n",
      "Epoch 0 batch 1028500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1029000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1029500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1030000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1030500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1031000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1031500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1032000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1032500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1033000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-111\n",
      "Epoch 0 batch 1033500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1034000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1034500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1035000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1035500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1036000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1036500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1037000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1037500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1038000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1038500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1039000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1039500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1040000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1040500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1041000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1041500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1042000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-112\n",
      "Epoch 0 batch 1042500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1043000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1043500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1044000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1044500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1045000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-113\n",
      "Epoch 0 batch 1045500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1046000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1046500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1047000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1047500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1048000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1048500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1049000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1049500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1050000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1050500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1051000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1051500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1052000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1052500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1053000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1053500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1054000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1054500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1055000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1055500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1056000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1056500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1057000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1057500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1058000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1058500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1059000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1059500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1060000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1060500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1061000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1061500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1062000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1062500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1063000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1063500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1064000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1064500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1065000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1065500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1066000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1066500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1067000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1067500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1068000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1068500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1069000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1069500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1070000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1070500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1071000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1071500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1072000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1072500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1073000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1073500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1074000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1074500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1075000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1075500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1076000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1076500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1077000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1077500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1078000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1078500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1079000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1079500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1080000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1080500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1081000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1081500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1082000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1082500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1083000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1083500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1084000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1084500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1085000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1085500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1086000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1086500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1087000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1087500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1088000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1088500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1089000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1089500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1090000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1090500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1091000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1091500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1092000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1092500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1093000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1093500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1094000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1094500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1095000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1095500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1096000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1096500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1097000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1097500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1098000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1098500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1099000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1099500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1100000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1100500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1101000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1101500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1102000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1102500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1103000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1103500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1104000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1104500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1105000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1105500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1106000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1106500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1107000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1107500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1108000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1108500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1109000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1109500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1110000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1110500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1111000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1111500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1112000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1112500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1113000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1113500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1114000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-114\n",
      "Epoch 0 batch 1114500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1115000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1115500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1116000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1116500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-115\n",
      "Epoch 0 batch 1117000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1117500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1118000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1118500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1119000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1119500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1120000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1120500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1121000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1121500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1122000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1122500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1123000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1123500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1124000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1124500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1125000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1125500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1126000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1126500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1127000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1127500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1128000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1128500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1129000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1129500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1130000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1130500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1131000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1131500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1132000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1132500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1133000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1133500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1134000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1134500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1135000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1135500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1136000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1136500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1137000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1137500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1138000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1138500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1139000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1139500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1140000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1140500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1141000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1141500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1142000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1142500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1143000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1143500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1144000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1144500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1145000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1145500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1146000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1146500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1147000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1147500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1148000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1148500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1149000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1149500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1150000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1150500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1151000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1151500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1152000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1152500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-116\n",
      "Epoch 0 batch 1153000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1153500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1154000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1154500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1155000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1155500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1156000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1156500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1157000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1157500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1158000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1158500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1159000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1159500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1160000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1160500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1161000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1161500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1162000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1162500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1163000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1163500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1164000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1164500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1165000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1165500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1166000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1166500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1167000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1167500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1168000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1168500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1169000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1169500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1170000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1170500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1171000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1171500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1172000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1172500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1173000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1173500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1174000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1174500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1175000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1175500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1176000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1176500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1177000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1177500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1178000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1178500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1179000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1179500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1180000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1180500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1181000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1181500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1182000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1182500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1183000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1183500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1184000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1184500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1185000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1185500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1186000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1186500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1187000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1187500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1188000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1188500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1189000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1189500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1190000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1190500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1191000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-117\n",
      "Epoch 0 batch 1191500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1192000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1192500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1193000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1193500 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-118\n",
      "Epoch 0 batch 1194000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1194500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1195000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1195500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1196000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1196500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1197000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1197500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1198000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1198500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1199000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1199500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1200000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1200500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1201000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1201500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1202000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1202500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1203000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1203500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1204000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1204500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1205000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1205500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1206000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1206500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1207000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1207500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1208000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1208500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1209000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1209500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1210000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1210500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1211000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1211500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1212000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1212500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1213000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1213500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1214000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1214500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1215000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1215500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1216000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1216500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1217000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1217500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1218000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1218500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1219000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1219500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1220000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1220500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1221000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1221500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1222000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1222500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1223000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1223500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1224000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1224500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1225000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1225500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1226000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1226500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1227000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1227500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1228000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1228500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1229000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1229500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1230000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1230500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1231000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1231500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1232000 train loss: 0.0000 test loss: 0.0001\n",
      "Saving checkpoint at ./checkpoints/trained_AE/ckpt-119\n",
      "Epoch 0 batch 1232500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1233000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1233500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1234000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1234500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1235000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1235500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1236000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1236500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1237000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1237500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1238000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1238500 train loss: 0.0000 test loss: 0.0002\n",
      "Epoch 0 batch 1239000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1239500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1240000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1240500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1241000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1241500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1242000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1242500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1243000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1243500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1244000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1244500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1245000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1245500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1246000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1246500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1247000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1247500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1248000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1248500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1249000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1249500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1250000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1250500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1251000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1251500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1252000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1252500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1253000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1253500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1254000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1254500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1255000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1255500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1256000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1256500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1257000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1257500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1258000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1258500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1259000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1259500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1260000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1260500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1261000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1261500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1262000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1262500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1263000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1263500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1264000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1264500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1265000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1265500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1266000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1266500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1267000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1267500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1268000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1268500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1269000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1269500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1270000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1270500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1271000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1271500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1272000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1272500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1273000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1273500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1274000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1274500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1275000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1275500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1276000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1276500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1277000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1277500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1278000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1278500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1279000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1279500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1280000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1280500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1281000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1281500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1282000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1282500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1283000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1283500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1284000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1284500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1285000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1285500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1286000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1286500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1287000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1287500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1288000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1288500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1289000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1289500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1290000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1290500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1291000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1291500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1292000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1292500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1293000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1293500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1294000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1294500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1295000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1295500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1296000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1296500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1297000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1297500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1298000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1298500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1299000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1299500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1300000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1300500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1301000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1301500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1302000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1302500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1303000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1303500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1304000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1304500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1305000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1305500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1306000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1306500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1307000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1307500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1308000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1308500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1309000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1309500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1310000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1310500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1311000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1311500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1312000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1312500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1313000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1313500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1314000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1314500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1315000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1315500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1316000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1316500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1317000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1317500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1318000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1318500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1319000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1319500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1320000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1320500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1321000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1321500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1322000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1322500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1323000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1323500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1324000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1324500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1325000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1325500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1326000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1326500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1327000 train loss: 0.0001 test loss: 0.0003\n",
      "Epoch 0 batch 1327500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1328000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1328500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1329000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1329500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1330000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1330500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1331000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1331500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1332000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1332500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1333000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1333500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1334000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1334500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1335000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1335500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1336000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1336500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1337000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1337500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1338000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1338500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1339000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1339500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1340000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1340500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1341000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1341500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1342000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1342500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1343000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1343500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1344000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1344500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1345000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1345500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1346000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1346500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1347000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1347500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1348000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1348500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1349000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1349500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1350000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1350500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1351000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1351500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1352000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1352500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1353000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1353500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1354000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1354500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1355000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1355500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1356000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1356500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1357000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1357500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1358000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1358500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1359000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1359500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1360000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1360500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1361000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1361500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1362000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1362500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1363000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1363500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1364000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1364500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1365000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1365500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1366000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1366500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1367000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1367500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1368000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1368500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1369000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1369500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1370000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1370500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1371000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1371500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1372000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1372500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1373000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1373500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1374000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1374500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1375000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1375500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1376000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1376500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1377000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1377500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1378000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1378500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1379000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1379500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1380000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1380500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1381000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1381500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1382000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1382500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1383000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1383500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1384000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1384500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1385000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1385500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1386000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1386500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1387000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1387500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1388000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1388500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1389000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1389500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1390000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1390500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1391000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1391500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1392000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1392500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1393000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1393500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1394000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1394500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1395000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1395500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1396000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1396500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1397000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1397500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1398000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1398500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1399000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1399500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1400000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1400500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1401000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1401500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1402000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1402500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1403000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1403500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1404000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1404500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1405000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1405500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1406000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1406500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1407000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1407500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1408000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1408500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1409000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1409500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1410000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1410500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1411000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1411500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1412000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1412500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1413000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1413500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1414000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1414500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1415000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1415500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1416000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1416500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1417000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1417500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1418000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1418500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1419000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1419500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1420000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1420500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1421000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1421500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1422000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1422500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1423000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1423500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1424000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1424500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1425000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1425500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1426000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1426500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1427000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1427500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1428000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1428500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1429000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1429500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1430000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1430500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1431000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1431500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1432000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1432500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1433000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1433500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1434000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1434500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1435000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1435500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1436000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1436500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1437000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1437500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1438000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1438500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1439000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1439500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1440000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1440500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1441000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1441500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1442000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1442500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1443000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1443500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1444000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1444500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1445000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1445500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1446000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1446500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1447000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1447500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1448000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1448500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1449000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1449500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1450000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1450500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1451000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1451500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1452000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1452500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1453000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1453500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1454000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1454500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1455000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1455500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1456000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1456500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1457000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1457500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1458000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1458500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1459000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1459500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1460000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1460500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1461000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1461500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1462000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1462500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1463000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1463500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1464000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1464500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1465000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1465500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1466000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1466500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1467000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1467500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1468000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1468500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1469000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1469500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1470000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1470500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1471000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1471500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1472000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1472500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1473000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1473500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1474000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1474500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1475000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1475500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1476000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1476500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1477000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1477500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1478000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1478500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1479000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1479500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1480000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1480500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1481000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1481500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1482000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1482500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1483000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1483500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1484000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1484500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1485000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1485500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1486000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1486500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1487000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1487500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1488000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1488500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1489000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1489500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1490000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1490500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1491000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1491500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1492000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1492500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1493000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1493500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1494000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1494500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1495000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1495500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1496000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1496500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1497000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1497500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1498000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1498500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1499000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1499500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1500000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1500500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1501000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1501500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1502000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1502500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1503000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1503500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1504000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1504500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1505000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1505500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1506000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1506500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1507000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1507500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1508000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1508500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1509000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1509500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1510000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1510500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1511000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1511500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1512000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1512500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1513000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1513500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1514000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1514500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1515000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1515500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1516000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1516500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1517000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1517500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1518000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1518500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1519000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1519500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1520000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1520500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1521000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1521500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1522000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1522500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1523000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1523500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1524000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1524500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1525000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1525500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1526000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1526500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1527000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1527500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1528000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1528500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1529000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1529500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1530000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1530500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1531000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1531500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1532000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1532500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1533000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1533500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1534000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1534500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1535000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1535500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1536000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1536500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1537000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1537500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1538000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1538500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1539000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1539500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1540000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1540500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1541000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1541500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1542000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1542500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1543000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1543500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1544000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1544500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1545000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1545500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1546000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1546500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1547000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1547500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1548000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1548500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1549000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1549500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1550000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1550500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1551000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1551500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1552000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1552500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1553000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1553500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1554000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1554500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1555000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1555500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1556000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1556500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1557000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1557500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1558000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1558500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1559000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1559500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1560000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1560500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1561000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1561500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1562000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1562500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1563000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1563500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1564000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1564500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1565000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1565500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1566000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1566500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1567000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1567500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1568000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1568500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1569000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1569500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1570000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1570500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1571000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1571500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1572000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1572500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1573000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1573500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1574000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1574500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1575000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1575500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1576000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1576500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1577000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1577500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1578000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1578500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1579000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1579500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1580000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1580500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1581000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1581500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1582000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1582500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1583000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1583500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1584000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1584500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1585000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1585500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1586000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1586500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1587000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1587500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1588000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1588500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1589000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1589500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1590000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1590500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1591000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1591500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1592000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1592500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1593000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1593500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1594000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1594500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1595000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1595500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1596000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1596500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1597000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1597500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1598000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1598500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1599000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1599500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1600000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1600500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1601000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1601500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1602000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1602500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1603000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1603500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1604000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1604500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1605000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1605500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1606000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1606500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1607000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1607500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1608000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1608500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1609000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1609500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1610000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1610500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1611000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1611500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1612000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1612500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1613000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1613500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1614000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1614500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1615000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1615500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1616000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1616500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1617000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1617500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1618000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1618500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1619000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1619500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1620000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1620500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1621000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1621500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1622000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1622500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1623000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1623500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1624000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1624500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1625000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1625500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1626000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1626500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1627000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1627500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1628000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1628500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1629000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1629500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1630000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1630500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1631000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1631500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1632000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1632500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1633000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1633500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1634000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1634500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1635000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1635500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1636000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1636500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1637000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1637500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1638000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1638500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1639000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1639500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1640000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1640500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1641000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1641500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1642000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1642500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1643000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1643500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1644000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1644500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1645000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1645500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1646000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1646500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1647000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1647500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1648000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1648500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1649000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1649500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1650000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1650500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1651000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1651500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1652000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1652500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1653000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1653500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1654000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1654500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1655000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1655500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1656000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1656500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1657000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1657500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1658000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1658500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1659000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1659500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1660000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1660500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1661000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1661500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1662000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1662500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1663000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1663500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1664000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1664500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1665000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1665500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1666000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1666500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1667000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1667500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1668000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1668500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1669000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1669500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1670000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1670500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1671000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1671500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1672000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1672500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1673000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1673500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1674000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1674500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1675000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1675500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1676000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1676500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1677000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1677500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1678000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1678500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1679000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1679500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1680000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1680500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1681000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1681500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1682000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1682500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1683000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1683500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1684000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1684500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1685000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1685500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1686000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1686500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1687000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1687500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1688000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1688500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1689000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1689500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1690000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1690500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1691000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1691500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1692000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1692500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1693000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1693500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1694000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1694500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1695000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1695500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1696000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1696500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1697000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1697500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1698000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1698500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1699000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1699500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1700000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1700500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1701000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1701500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1702000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1702500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1703000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1703500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1704000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1704500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1705000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1705500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1706000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1706500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1707000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1707500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1708000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1708500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1709000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1709500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1710000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1710500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1711000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1711500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1712000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1712500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1713000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1713500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1714000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1714500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1715000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1715500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1716000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1716500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1717000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1717500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1718000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1718500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1719000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1719500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1720000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1720500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1721000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1721500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1722000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1722500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1723000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1723500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1724000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1724500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1725000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1725500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1726000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1726500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1727000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1727500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1728000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1728500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1729000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1729500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1730000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1730500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1731000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1731500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1732000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1732500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1733000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1733500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1734000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1734500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1735000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1735500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1736000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1736500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1737000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1737500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1738000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1738500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1739000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1739500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1740000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1740500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1741000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1741500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1742000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1742500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1743000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1743500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1744000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1744500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1745000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1745500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1746000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1746500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1747000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1747500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1748000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1748500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1749000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1749500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1750000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1750500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1751000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1751500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1752000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1752500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1753000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1753500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1754000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1754500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1755000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1755500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1756000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1756500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1757000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1757500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1758000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1758500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1759000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1759500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1760000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1760500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1761000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1761500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1762000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1762500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1763000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1763500 train loss: 0.0000 test loss: 0.0002\n",
      "Epoch 0 batch 1764000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1764500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1765000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1765500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1766000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1766500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1767000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1767500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1768000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1768500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1769000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1769500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1770000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1770500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1771000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1771500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1772000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1772500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1773000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1773500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1774000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1774500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1775000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1775500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1776000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1776500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1777000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1777500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1778000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1778500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1779000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1779500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1780000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1780500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1781000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1781500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1782000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1782500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1783000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1783500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1784000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1784500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1785000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1785500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1786000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1786500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1787000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1787500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1788000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1788500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1789000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1789500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1790000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1790500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1791000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1791500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1792000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1792500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1793000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1793500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1794000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1794500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1795000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1795500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1796000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1796500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1797000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1797500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1798000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1798500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1799000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1799500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1800000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1800500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1801000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1801500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1802000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1802500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1803000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1803500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1804000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1804500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1805000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1805500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1806000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1806500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1807000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1807500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1808000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1808500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1809000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1809500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1810000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1810500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1811000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1811500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1812000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1812500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1813000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1813500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1814000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1814500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1815000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1815500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1816000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1816500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1817000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1817500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1818000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1818500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1819000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1819500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1820000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1820500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1821000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1821500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1822000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1822500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1823000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1823500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1824000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1824500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1825000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1825500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1826000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1826500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1827000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1827500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1828000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1828500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1829000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1829500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1830000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1830500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1831000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1831500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1832000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1832500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1833000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1833500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1834000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1834500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1835000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1835500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1836000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1836500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1837000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1837500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1838000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1838500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1839000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1839500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1840000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1840500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1841000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1841500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1842000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1842500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1843000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1843500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1844000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1844500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1845000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1845500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1846000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1846500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1847000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1847500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1848000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1848500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1849000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1849500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1850000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1850500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1851000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1851500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1852000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1852500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1853000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1853500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1854000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1854500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1855000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1855500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1856000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1856500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1857000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1857500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1858000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1858500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1859000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1859500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1860000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1860500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1861000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1861500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1862000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1862500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1863000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1863500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1864000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1864500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1865000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1865500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1866000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1866500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1867000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1867500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1868000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1868500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1869000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1869500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1870000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1870500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1871000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1871500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1872000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1872500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1873000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1873500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1874000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1874500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1875000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1875500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1876000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1876500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1877000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1877500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1878000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1878500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1879000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1879500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1880000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1880500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1881000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1881500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1882000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1882500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1883000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1883500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1884000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1884500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1885000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1885500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1886000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1886500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1887000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1887500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1888000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1888500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1889000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1889500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1890000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1890500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1891000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1891500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1892000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1892500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1893000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1893500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1894000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1894500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1895000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1895500 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1896000 train loss: 0.0000 test loss: 0.0001\n",
      "Epoch 0 batch 1896500 train loss: 0.0000 test loss: 0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-601b5d3667ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                 \u001b[0mloss_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf20/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf20/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf20/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf20/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf20/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tf20/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.virtualenvs/tf20/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "prev_test_loss = 100.0\n",
    "with writer.as_default():\n",
    "    with tf.summary.record_if(True):\n",
    "        for epoch in range(EPOCHS):\n",
    "            for step, (inp, tar) in enumerate(train_dataset):\n",
    "                train(loss, autoencoder, opt, inp)\n",
    "                loss_values = loss(autoencoder, inp)\n",
    "                tf.summary.scalar('loss', loss_values, step=step)\n",
    "                \n",
    "                if step % 500 == 0:\n",
    "                    test_loss = 0\n",
    "                    for step_, (inp_, tar_) in enumerate(test_dataset):\n",
    "                        test_loss += loss(autoencoder, inp_)\n",
    "                        \n",
    "                        if step_ > 500:\n",
    "                            test_loss /= 100\n",
    "                            break\n",
    "                    if test_loss.numpy() < prev_test_loss:\n",
    "                        ckpt_save_path = ckpt_manager.save()\n",
    "                        prev_test_loss = test_loss.numpy()\n",
    "                        print('Saving checkpoint at {}'.format(ckpt_save_path))\n",
    "                    print('Epoch {} batch {} train loss: {:.4f} test loss: {:.4f}'\n",
    "                          .format(epoch, step, loss_values.numpy(), test_loss.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNhuYfllndLZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint pt-119 restored!!\n"
     ]
    }
   ],
   "source": [
    "i = -1\n",
    "if ckpt_manager.checkpoints:\n",
    "    ckpt.restore(ckpt_manager.checkpoints[i])\n",
    "    print ('Checkpoint ' + ckpt_manager.checkpoints[i][-6:] +' restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "for step_, (inp_, tar_) in enumerate(test_dataset):\n",
    "    test_loss += loss(autoencoder, inp_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save_weights('./checkpoints/trained_AE')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf20",
   "language": "python",
   "name": "tf20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
