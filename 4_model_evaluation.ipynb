{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Metric\n",
    "class RSquare(Metric):\n",
    "    \"\"\"Compute R^2 score.\n",
    "     This is also called as coefficient of determination.\n",
    "     It tells how close are data to the fitted regression line.\n",
    "     - Highest score can be 1.0 and it indicates that the predictors\n",
    "       perfectly accounts for variation in the target.\n",
    "     - Score 0.0 indicates that the predictors do not\n",
    "       account for variation in the target.\n",
    "     - It can also be negative if the model is worse.\n",
    "     Usage:\n",
    "     ```python\n",
    "     actuals = tf.constant([1, 4, 3], dtype=tf.float32)\n",
    "     preds = tf.constant([2, 4, 4], dtype=tf.float32)\n",
    "     result = tf.keras.metrics.RSquare()\n",
    "     result.update_state(actuals, preds)\n",
    "     print('R^2 score is: ', r1.result().numpy()) # 0.57142866\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name='r_square', dtype=tf.float32):\n",
    "        super(RSquare, self).__init__(name=name, dtype=dtype)\n",
    "        self.squared_sum = self.add_weight(\"squared_sum\", initializer=\"zeros\")\n",
    "        self.sum = self.add_weight(\"sum\", initializer=\"zeros\")\n",
    "        self.res = self.add_weight(\"residual\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred):\n",
    "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
    "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
    "        self.squared_sum.assign_add(tf.reduce_sum(y_true**2))\n",
    "        self.sum.assign_add(tf.reduce_sum(y_true))\n",
    "        self.res.assign_add(\n",
    "            tf.reduce_sum(tf.square(tf.subtract(y_true, y_pred))))\n",
    "        self.count.assign_add(tf.cast(tf.shape(y_true)[0], tf.float32))\n",
    "\n",
    "    def result(self):\n",
    "        mean = self.sum / self.count\n",
    "        total = self.squared_sum - 2 * self.sum * mean + self.count * mean**2\n",
    "        return 1 - (self.res / total)\n",
    "\n",
    "    def reset_states(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.squared_sum.assign(0.0)\n",
    "        self.sum.assign(0.0)\n",
    "        self.res.assign(0.0)\n",
    "        self.count.assign(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import (LinearLocator, MultipleLocator, FormatStrFormatter)\n",
    "from matplotlib.dates import MONDAY\n",
    "from matplotlib.dates import MonthLocator, WeekdayLocator, DateFormatter\n",
    "from matplotlib import gridspec\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = ((8/2.54), (6/2.54))\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"mathtext.default\"] = \"rm\"\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "MARKER_SIZE = 15\n",
    "cmap_m = [\"#f4a6ad\", \"#f6957e\", \"#fccfa2\", \"#8de7be\", \"#86d6f2\", \"#24a9e4\", \"#b586e0\", \"#d7f293\"]\n",
    "cmap = [\"#e94d5b\", \"#ef4d28\", \"#f9a54f\", \"#25b575\", \"#1bb1e7\", \"#1477a2\", \"#a662e5\", \"#c2f442\"]\n",
    "\n",
    "plt.rcParams['axes.spines.top'] = False\n",
    "# plt.rcParams['axes.edgecolor'] = \n",
    "plt.rcParams['axes.linewidth'] = 1\n",
    "plt.rcParams['lines.linewidth'] = 1.5\n",
    "plt.rcParams['xtick.major.width'] = 1\n",
    "plt.rcParams['xtick.minor.width'] = 1\n",
    "plt.rcParams['ytick.major.width'] = 1\n",
    "plt.rcParams['ytick.minor.width'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_patch_spines_invisible(ax):\n",
    "    ax.set_frame_on(True)\n",
    "    ax.patch.set_visible(False)\n",
    "    for sp in ax.spines.values():\n",
    "        sp.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_PATHS       = ['./models/best_MLP.h5', \n",
    "                    './models/best_LSTM.h5',\n",
    "                    './models/best_AE_LSTM.h5',\n",
    "                    './models/best_BiLSTM.h5',\n",
    "                    './models/best_AE_BiLSTM.h5']\n",
    "TRANS_BEST_PATHS = ['./models/trans_MLP.h5', \n",
    "                    './models/trans_LSTM.h5',\n",
    "                    './models/trans_AE_LSTM.h5',\n",
    "                    './models/trans_BiLSTM.h5',\n",
    "                    './models/trans_AE_BiLSTM.h5']\n",
    "RAW_BEST_PATHS   = ['./models/raw_MLP.h5', \n",
    "                    './models/raw_LSTM.h5',\n",
    "                    './models/raw_AE_LSTM.h5',\n",
    "                    './models/raw_BiLSTM.h5',\n",
    "                    './models/raw_AE_BiLSTM.h5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.load('./env_set/dataset.npz')\n",
    "train_input = l['train_input']\n",
    "train_label = l['train_label']\n",
    "test_input = l['test_input']\n",
    "test_label = l['test_label']\n",
    "MAXS = l['MAXS']\n",
    "MINS = l['MINS']\n",
    "\n",
    "TIME_STEPS = l['TIME_STEPS']\n",
    "OUTPUT_SIZE = l['OUTPUT_SIZE']\n",
    "NUM_FEATURES = train_input.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41025, 24, 5)\n",
      "(41025, 24, 5)\n",
      "\n",
      "(16119, 24, 5)\n",
      "(16119, 24, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape)\n",
    "print(train_label.shape)\n",
    "print()\n",
    "print(test_input.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_input, test_label))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrainLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_hidden, activation=tf.nn.relu):\n",
    "        super(RetrainLayer, self).__init__()\n",
    "        self.num_hidden = num_hidden\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(self.num_hidden, activation=activation, kernel_initializer='he_uniform')\n",
    "        \n",
    "    def call(self, inp):\n",
    "        return self.dense(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_hiddens, encoding_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.encoding_size = encoding_size\n",
    "        \n",
    "        self.denses = [tf.keras.layers.Dense(self.num_hiddens[_], activation=tf.nn.relu, kernel_initializer='he_uniform')\n",
    "                       for _ in range(len(self.num_hiddens))]\n",
    "        \n",
    "        self.output_layer = tf.keras.layers.Dense(self.encoding_size, activation=tf.nn.sigmoid)\n",
    "        \n",
    "    def call(self, inp):\n",
    "        for _ in range(len(self.num_hiddens)):\n",
    "            inp = self.denses[_](inp)\n",
    "        \n",
    "        return self.output_layer(inp)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_hiddens, original_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.num_hiddens = num_hiddens[::-1]\n",
    "        self.original_size = original_size\n",
    "        \n",
    "        self.denses = [tf.keras.layers.Dense(self.num_hiddens[_], activation=tf.nn.relu, kernel_initializer='he_uniform')\n",
    "                       for _ in range(len(self.num_hiddens))]\n",
    "        \n",
    "    def call(self, inp):\n",
    "        for _ in range(len(self.num_hiddens)):\n",
    "            inp = self.denses[_](inp)\n",
    "        \n",
    "        return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    def __init__(self, num_hiddens, encoding_size, original_size):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.encoding_size = encoding_size\n",
    "        self.original_size = original_size\n",
    "        \n",
    "        self.in_retrain_layer = RetrainLayer(self.num_hiddens[0])\n",
    "        self.encoder = Encoder(self.num_hiddens, self.encoding_size)\n",
    "        self.decoder = Decoder(self.num_hiddens, self.original_size)\n",
    "        self.out_retrain_layer = RetrainLayer(self.original_size, activation = tf.nn.sigmoid)\n",
    "        \n",
    "    def call(self, inp, need_code=False, decoding=None):\n",
    "        inp = self.in_retrain_layer(inp)\n",
    "        encoded_values = self.encoder(inp)\n",
    "        if decoding is not None:\n",
    "            decoding = self.decoder(decoding)\n",
    "            return self.out_retrain_layer(decoding)\n",
    "        if not need_code:\n",
    "            encoded_values = self.decoder(encoded_values)\n",
    "            return self.out_retrain_layer(encoded_values)\n",
    "        else:\n",
    "            return encoded_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens = [32, 16]\n",
    "encoding_size = 8\n",
    "original_size = 5\n",
    "autoencoder = Autoencoder(num_hiddens, encoding_size, original_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f278c2da588>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.load_weights('./checkpoints/trained_AE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = tf.keras.models.load_model(BEST_PATHS[0])\n",
    "lstm_model = tf.keras.models.load_model(BEST_PATHS[1])\n",
    "bilstm_model = tf.keras.models.load_model(BEST_PATHS[3])\n",
    "ae_lstm_model = tf.keras.models.load_model(BEST_PATHS[2])\n",
    "ae_bilstm_model = tf.keras.models.load_model(BEST_PATHS[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation w/o transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_pred = mlp_model.predict(test_dataset)\n",
    "lstm_pred = lstm_model.predict(test_dataset)\n",
    "bilstm_pred = bilstm_model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer autoencoder is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_test_input = []\n",
    "encoded_test_label = []\n",
    "for step, (inp, tar) in enumerate(test_dataset):\n",
    "    encoded_test_input.append(autoencoder(inp, True))\n",
    "    encoded_test_label.append(autoencoder(tar, True))\n",
    "encoded_test_input = np.concatenate(encoded_test_input, axis=0)\n",
    "encoded_test_label = np.concatenate(encoded_test_label, axis=0)\n",
    "encoded_test_dataset = tf.data.Dataset.from_tensor_slices((encoded_test_input, encoded_test_label))\n",
    "encoded_test_dataset = encoded_test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ae_lstm_model.predict(encoded_test_dataset)\n",
    "ae_lstm_pred = autoencoder(train_input[0:1, :, :], decoding=_)\n",
    "_ = ae_bilstm_model.predict(encoded_test_dataset)\n",
    "ae_bilstm_pred = autoencoder(train_input[0:1, :, :], decoding=_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = tf.cast((MAXS-MINS)*test_label + MINS, tf.float32).numpy()\n",
    "mlp_pred = tf.cast((MAXS-MINS)*mlp_pred + MINS, tf.float32).numpy()\n",
    "lstm_pred = tf.cast((MAXS-MINS)*lstm_pred + MINS, tf.float32).numpy()\n",
    "bilstm_pred = tf.cast((MAXS-MINS)*bilstm_pred + MINS, tf.float32).numpy()\n",
    "ae_lstm_pred = tf.cast((MAXS-MINS)*ae_lstm_pred + MINS, tf.float32).numpy()\n",
    "ae_bilstm_pred = tf.cast((MAXS-MINS)*ae_bilstm_pred + MINS, tf.float32).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_label.reshape(-1, 5), columns=['T_in', 'T_out', 'RH_in', 'CO2', 'Rad']).to_csv('./results/test_label.csv')\n",
    "pd.DataFrame(mlp_pred.reshape(-1, 5), columns=['T_in', 'T_out', 'RH_in', 'CO2', 'Rad']).to_csv('./results/mlp_pred.csv')\n",
    "pd.DataFrame(lstm_pred.reshape(-1, 5), columns=['T_in', 'T_out', 'RH_in', 'CO2', 'Rad']).to_csv('./results/lstm_pred.csv')\n",
    "pd.DataFrame(bilstm_pred.reshape(-1, 5), columns=['T_in', 'T_out', 'RH_in', 'CO2', 'Rad']).to_csv('./results/bilstm_pred.csv')\n",
    "pd.DataFrame(ae_lstm_pred.reshape(-1, 5), columns=['T_in', 'T_out', 'RH_in', 'CO2', 'Rad']).to_csv('./results/ae_lstm_pred.csv')\n",
    "pd.DataFrame(ae_bilstm_pred.reshape(-1, 5), columns=['T_in', 'T_out', 'RH_in', 'CO2', 'Rad']).to_csv('./results/ae_bilstm_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation w/ transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.load('./env_set/val_dataset.npz')\n",
    "train_input = l['train_input']\n",
    "train_label = l['train_label']\n",
    "test_input = l['test_input']\n",
    "test_label = l['test_label']\n",
    "MAXS = l['MAXS']\n",
    "MINS = l['MINS']\n",
    "\n",
    "TIME_STEPS = l['TIME_STEPS']\n",
    "OUTPUT_SIZE = l['OUTPUT_SIZE']\n",
    "NUM_FEATURES = train_input.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_input.shape)\n",
    "print(train_label.shape)\n",
    "print()\n",
    "print(test_input.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_input, test_label))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_pred = mlp_model.predict(test_dataset)\n",
    "lstm_pred = lstm_model.predict(test_dataset)\n",
    "bilstm_pred = bilstm_model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test_input = []\n",
    "encoded_test_label = []\n",
    "for step, (inp, tar) in enumerate(test_dataset):\n",
    "    encoded_test_input.append(autoencoder(inp, True))\n",
    "    encoded_test_label.append(autoencoder(tar, True))\n",
    "encoded_test_input = np.concatenate(encoded_test_input, axis=0)\n",
    "encoded_test_label = np.concatenate(encoded_test_label, axis=0)\n",
    "encoded_test_dataset = tf.data.Dataset.from_tensor_slices((encoded_test_input, encoded_test_label))\n",
    "encoded_test_dataset = encoded_test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ae_lstm_model.predict(encoded_test_dataset)\n",
    "ae_lstm_pred = autoencoder(train_input[0:1, :, :], decoding=_)\n",
    "_ = ae_bilstm_model.predict(encoded_test_dataset)\n",
    "ae_bilstm_pred = autoencoder(train_input[0:1, :, :], decoding=_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = tf.cast((MAXS-MINS)*test_label + MINS, tf.float32).numpy()\n",
    "mlp_pred = tf.cast((MAXS-MINS)*mlp_pred + MINS, tf.float32).numpy()\n",
    "lstm_pred = tf.cast((MAXS-MINS)*lstm_pred + MINS, tf.float32).numpy()\n",
    "bilstm_pred = tf.cast((MAXS-MINS)*bilstm_pred + MINS, tf.float32).numpy()\n",
    "ae_lstm_pred = tf.cast((MAXS-MINS)*ae_lstm_pred + MINS, tf.float32).numpy()\n",
    "ae_bilstm_pred = tf.cast((MAXS-MINS)*ae_bilstm_pred + MINS, tf.float32).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_label.reshape(-1, 5), columns=['T_in', 'T_out', 'RH_in', 'CO2', 'Rad']).to_csv('./results/val_test_label.csv')\n",
    "pd.DataFrame(mlp_pred.reshape(-1, 5), columns=['T_in', 'T_out', 'RH_in', 'CO2', 'Rad']).to_csv('./results/val_mlp_pred.csv')\n",
    "pd.DataFrame(lstm_pred.reshape(-1, 5), columns=['T_in', 'T_out', 'RH_in', 'CO2', 'Rad']).to_csv('./results/val_lstm_pred.csv')\n",
    "pd.DataFrame(bilstm_pred.reshape(-1, 5), columns=['T_in', 'T_out', 'RH_in', 'CO2', 'Rad']).to_csv('./results/val_bilstm_pred.csv')\n",
    "pd.DataFrame(ae_lstm_pred.reshape(-1, 5), columns=['T_in', 'T_out', 'RH_in', 'CO2', 'Rad']).to_csv('./results/val_ae_lstm_pred.csv')\n",
    "pd.DataFrame(ae_bilstm_pred.reshape(-1, 5), columns=['T_in', 'T_out', 'RH_in', 'CO2', 'Rad']).to_csv('./results/val_ae_bilstm_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.load('./env_set/val_dataset.npz')\n",
    "train_input = l['train_input']\n",
    "train_label = l['train_label']\n",
    "test_input = l['test_input']\n",
    "test_label = l['test_label']\n",
    "MAXS = l['MAXS']\n",
    "MINS = l['MINS']\n",
    "\n",
    "TIME_STEPS = l['TIME_STEPS']\n",
    "OUTPUT_SIZE = l['OUTPUT_SIZE']\n",
    "NUM_FEATURES = train_input.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_input.shape)\n",
    "print(train_label.shape)\n",
    "print()\n",
    "print(test_input.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_input, test_label))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens = [32, 16]\n",
    "encoding_size = 8\n",
    "original_size = 5\n",
    "trans_ae = Autoencoder(num_hiddens, encoding_size, original_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_ae.load_weights('./models/trans_ae')\n",
    "print('transfered AE is ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_mlp_model = tf.keras.models.load_model(TRANS_BEST_PATHS[0])\n",
    "tr_lstm_model = tf.keras.models.load_model(TRANS_BEST_PATHS[1])\n",
    "tr_bilstm_model = tf.keras.models.load_model(TRANS_BEST_PATHS[3])\n",
    "tr_ae_lstm_model = tf.keras.models.load_model(TRANS_BEST_PATHS[2])\n",
    "tr_ae_bilstm_model = tf.keras.models.load_model(TRANS_BEST_PATHS[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_ae.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_mlp_pred = tr_mlp_model.predict(test_dataset)\n",
    "tr_lstm_pred = tr_lstm_model.predict(test_dataset)\n",
    "tr_bilstm_pred = tr_bilstm_model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_test_input = []\n",
    "encoded_test_label = []\n",
    "for step, (inp, tar) in enumerate(test_dataset):\n",
    "    encoded_test_input.append(trans_ae(inp, True))\n",
    "    encoded_test_label.append(trans_ae(tar, True))\n",
    "encoded_test_input = np.concatenate(encoded_test_input, axis=0)\n",
    "encoded_test_label = np.concatenate(encoded_test_label, axis=0)\n",
    "encoded_test_dataset = tf.data.Dataset.from_tensor_slices((encoded_test_input, encoded_test_label))\n",
    "encoded_test_dataset = encoded_test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tr_ae_lstm_model.predict(encoded_test_dataset)\n",
    "tr_ae_lstm_pred = trans_ae(train_input[0:1, :, :], decoding=_)\n",
    "_ = tr_ae_bilstm_model.predict(encoded_test_dataset)\n",
    "tr_ae_bilstm_pred = trans_ae(train_input[0:1, :, :], decoding=_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = tf.cast((MAXS-MINS)*test_label + MINS, tf.float32).numpy()\n",
    "tr_mlp_pred = tf.cast((MAXS-MINS)*tr_mlp_pred + MINS, tf.float32).numpy()\n",
    "tr_lstm_pred = tf.cast((MAXS-MINS)*tr_lstm_pred + MINS, tf.float32).numpy()\n",
    "tr_bilstm_pred = tf.cast((MAXS-MINS)*tr_bilstm_pred + MINS, tf.float32).numpy()\n",
    "tr_ae_lstm_pred = tf.cast((MAXS-MINS)*tr_ae_lstm_pred + MINS, tf.float32).numpy()\n",
    "tr_ae_bilstm_pred = tf.cast((MAXS-MINS)*tr_ae_bilstm_pred + MINS, tf.float32).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_label.reshape(-1, 5), columns=['T_in', 'T_out', 'RH_in', 'CO2', 'Rad']).to_csv('./results/val_tr_test_label.csv')\n",
    "pd.DataFrame(tr_mlp_pred.reshape(-1, 5), columns=['T_in', 'T_out', 'RH_in', 'CO2', 'Rad']).to_csv('./results/val_tr_mlp_pred.csv')\n",
    "pd.DataFrame(tr_lstm_pred.reshape(-1, 5), columns=['T_in', 'T_out', 'RH_in', 'CO2', 'Rad']).to_csv('./results/val_tr_lstm_pred.csv')\n",
    "pd.DataFrame(tr_bilstm_pred.reshape(-1, 5), columns=['T_in', 'T_out', 'RH_in', 'CO2', 'Rad']).to_csv('./results/val_tr_bilstm_pred.csv')\n",
    "pd.DataFrame(tr_ae_lstm_pred.reshape(-1, 5), columns=['T_in', 'T_out', 'RH_in', 'CO2', 'Rad']).to_csv('./results/val_tr_ae_lstm_pred.csv')\n",
    "pd.DataFrame(tr_ae_bilstm_pred.reshape(-1, 5), columns=['T_in', 'T_out', 'RH_in', 'CO2', 'Rad']).to_csv('./results/val_tr_ae_bilstm_pred.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation w/ transfer (tom)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf20",
   "language": "python",
   "name": "tf20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
