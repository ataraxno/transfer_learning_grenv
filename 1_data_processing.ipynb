{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 24\n",
    "OUTPUT_SIZE = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = './env_set/'\n",
    "file_list = os.listdir(DIRECTORY)\n",
    "dataset_list = [file for file in file_list if file.endswith('.csv') and not file.startswith('Val')]\n",
    "dataset_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PF_0000336_pap_env.csv',\n",
       " 'PF_0000587_pap_env.csv',\n",
       " 'PF_0001122_pap_env.csv',\n",
       " 'PF_0001284_pap_env.csv',\n",
       " 'PF_0001394_pap_env.csv',\n",
       " 'PF_0001399_pap_env.csv',\n",
       " 'PF_0001401_pap_env.csv',\n",
       " 'PF_0001403_pap_env.csv',\n",
       " 'PF_0002322_pap_env.csv',\n",
       " 'PF_0002633_pap_env.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2461.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data = []\n",
    "for FILENAME in dataset_list:\n",
    "    env_df = pd.read_csv(DIRECTORY + FILENAME, index_col=['MEAS_DATE']).dropna(how='all')\n",
    "    env_df = env_df[~(env_df == 0).all(axis=1)].interpolate().values\n",
    "    num_data.append(env_df.shape[0]/24)\n",
    "num_data = np.array(num_data)\n",
    "num_data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train_df = []\n",
    "temp_train_input = []\n",
    "temp_train_label = []\n",
    "temp_test_df = []\n",
    "temp_test_input = []\n",
    "temp_test_label = []\n",
    "for FILENAME in dataset_list:\n",
    "    env_df = pd.read_csv(DIRECTORY + FILENAME, index_col=['MEAS_DATE']).dropna(how='all')\n",
    "    env_df = env_df[~(env_df == 0).all(axis=1)].interpolate().values\n",
    "    np.random.seed(3101)\n",
    "    slicer = int((env_df.shape[0]-OUTPUT_SIZE - TIME_STEPS)/10)\n",
    "    test_index_start = (np.random.choice(10, 3, replace=False)*slicer).astype('int')\n",
    "    test_index_bound = np.concatenate([np.arange(_+TIME_STEPS, _+slicer-OUTPUT_SIZE) for _ in test_index_start])\n",
    "    test_index_start = np.concatenate([np.arange(_, _+slicer) for _ in test_index_start])\n",
    "    for INDEX in range(TIME_STEPS, env_df.shape[0]-OUTPUT_SIZE):\n",
    "        if INDEX in test_index_start:\n",
    "            if INDEX in test_index_bound:\n",
    "                temp_test_input.append(env_df[(INDEX-TIME_STEPS):INDEX, :])\n",
    "                temp_test_label.append(env_df[INDEX:(INDEX+OUTPUT_SIZE), :])\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            temp_train_input.append(env_df[(INDEX-TIME_STEPS):INDEX, :])\n",
    "            temp_train_label.append(env_df[INDEX:(INDEX+OUTPUT_SIZE), :])\n",
    "train_input = np.concatenate(temp_train_input)\n",
    "train_label = np.concatenate(temp_train_label)\n",
    "test_input = np.concatenate(temp_test_input)\n",
    "test_label = np.concatenate(temp_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXS = train_input.max(axis=0)\n",
    "MINS = train_input.min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = train_input.reshape(-1, TIME_STEPS, env_df.shape[-1])\n",
    "train_label = train_label.reshape(-1, OUTPUT_SIZE, env_df.shape[-1])\n",
    "test_input = test_input.reshape(-1, TIME_STEPS, env_df.shape[-1])\n",
    "test_label = test_label.reshape(-1, OUTPUT_SIZE, env_df.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41025, 24, 5)\n",
      "(41025, 24, 5)\n",
      "(16119, 24, 5)\n",
      "(16119, 24, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape)\n",
    "print(train_label.shape)\n",
    "print(test_input.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  42.4    37.35  100.   2999.    969.27]\n",
      "[  8.15 -20.92  27.87   1.67   0.  ]\n"
     ]
    }
   ],
   "source": [
    "print(MAXS)\n",
    "print(MINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = (train_input - MINS) / (MAXS - MINS)\n",
    "train_label = (train_label - MINS) / (MAXS - MINS)\n",
    "\n",
    "test_input = (test_input - MINS) / (MAXS - MINS)\n",
    "test_label = (test_label - MINS) / (MAXS - MINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41025, 24, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "[1.         1.         1.         1.         1.06028248]\n",
      "\n",
      "[1.36437956 0.9689377  1.         0.9964802  0.98788779]\n",
      "[1.36437956 0.9689377  1.         0.9964802  0.98788779]\n"
     ]
    }
   ],
   "source": [
    "print(train_input.max(axis=0).max(axis=0))\n",
    "print(train_label.max(axis=0).max(axis=0))\n",
    "print()\n",
    "print(test_input.max(axis=0).max(axis=0))\n",
    "print(test_label.max(axis=0).max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41025, 24, 5)\n",
      "(41025, 24, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16119, 24, 5)\n",
      "(16119, 24, 5)\n"
     ]
    }
   ],
   "source": [
    "print(test_input.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./env_set/dataset.npz', 'wb')\n",
    "np.savez(f,\n",
    "         train_input = train_input,\n",
    "         train_label = train_label,\n",
    "         test_input = test_input,\n",
    "         test_label = test_label,\n",
    "         MAXS = MAXS,\n",
    "         MINS = MINS,\n",
    "         TIME_STEPS = TIME_STEPS,\n",
    "         OUTPUT_SIZE = OUTPUT_SIZE\n",
    "        )\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = './env_set/'\n",
    "file_list = os.listdir(DIRECTORY)\n",
    "dataset_list = [file for file in file_list if file.endswith('.csv') and file.startswith('Val')]\n",
    "dataset_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Val_PF_0001288_pap_env.csv',\n",
       " 'Val_PF_0001393_pap_env.csv',\n",
       " 'Val_PF_0001400_pap_env.csv',\n",
       " 'Val_PF_0002537_pap_env.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1343.9583333333335"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data = []\n",
    "for FILENAME in dataset_list:\n",
    "    env_df = pd.read_csv(DIRECTORY + FILENAME, index_col=['MEAS_DATE']).dropna(how='all')\n",
    "    env_df = env_df[~(env_df == 0).all(axis=1)].interpolate().values\n",
    "    num_data.append(env_df.shape[0]/24)\n",
    "num_data = np.array(num_data)\n",
    "num_data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train_df = []\n",
    "temp_train_input = []\n",
    "temp_train_label = []\n",
    "temp_test_df = []\n",
    "temp_test_input = []\n",
    "temp_test_label = []\n",
    "for FILENAME in dataset_list:\n",
    "    env_df = pd.read_csv(DIRECTORY + FILENAME, index_col=['MEAS_DATE']).dropna(how='all')\n",
    "    env_df = env_df[~(env_df == 0).all(axis=1)].interpolate().values\n",
    "    np.random.seed(3101)\n",
    "    slicer = int((env_df.shape[0]-OUTPUT_SIZE - TIME_STEPS)/10)\n",
    "    test_index_start = (np.random.choice(10, 7, replace=False)*slicer).astype('int')\n",
    "    test_index_bound = np.concatenate([np.arange(_+TIME_STEPS, _+slicer-OUTPUT_SIZE) for _ in test_index_start])\n",
    "    test_index_start = np.concatenate([np.arange(_, _+slicer) for _ in test_index_start])\n",
    "    for INDEX in range(TIME_STEPS, env_df.shape[0]-OUTPUT_SIZE):\n",
    "        if INDEX in test_index_start:\n",
    "            if INDEX in test_index_bound:\n",
    "                temp_test_input.append(env_df[(INDEX-TIME_STEPS):INDEX, :])\n",
    "                temp_test_label.append(env_df[INDEX:(INDEX+OUTPUT_SIZE), :])\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            temp_train_input.append(env_df[(INDEX-TIME_STEPS):INDEX, :])\n",
    "            temp_train_label.append(env_df[INDEX:(INDEX+OUTPUT_SIZE), :])\n",
    "train_input = np.concatenate(temp_train_input)\n",
    "train_label = np.concatenate(temp_train_label)\n",
    "test_input = np.concatenate(temp_test_input)\n",
    "test_label = np.concatenate(temp_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = train_input.reshape(-1, TIME_STEPS, env_df.shape[-1])\n",
    "train_label = train_label.reshape(-1, OUTPUT_SIZE, env_df.shape[-1])\n",
    "test_input = test_input.reshape(-1, TIME_STEPS, env_df.shape[-1])\n",
    "test_label = test_label.reshape(-1, OUTPUT_SIZE, env_df.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9731, 24, 5)\n",
      "(9731, 24, 5)\n",
      "(21084, 24, 5)\n",
      "(21084, 24, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape)\n",
    "print(train_label.shape)\n",
    "print(test_input.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  42.4    37.35  100.   2999.    969.27]\n",
      "[  8.15 -20.92  27.87   1.67   0.  ]\n"
     ]
    }
   ],
   "source": [
    "print(MAXS)\n",
    "print(MINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = (train_input - MINS) / (MAXS - MINS)\n",
    "train_label = (train_label - MINS) / (MAXS - MINS)\n",
    "\n",
    "test_input = (test_input - MINS) / (MAXS - MINS)\n",
    "test_label = (test_label - MINS) / (MAXS - MINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9731, 24, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.34540146 0.99502317 1.0176071  0.99899911 0.98769177]\n",
      "[1.34540146 0.99502317 1.0176071  0.99899911 0.98769177]\n",
      "\n",
      "[1.09138686 0.99038957 1.         0.75523216 1.01530017]\n",
      "[1.09138686 0.99038957 1.         0.75523216 1.01530017]\n"
     ]
    }
   ],
   "source": [
    "print(train_input.max(axis=0).max(axis=0))\n",
    "print(train_label.max(axis=0).max(axis=0))\n",
    "print()\n",
    "print(test_input.max(axis=0).max(axis=0))\n",
    "print(test_label.max(axis=0).max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9731, 24, 5)\n",
      "(9731, 24, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21084, 24, 5)\n",
      "(21084, 24, 5)\n"
     ]
    }
   ],
   "source": [
    "print(test_input.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./env_set/val_dataset.npz', 'wb')\n",
    "np.savez(f,\n",
    "         train_input = train_input,\n",
    "         train_label = train_label,\n",
    "         test_input = test_input,\n",
    "         test_label = test_label,\n",
    "         MAXS = MAXS,\n",
    "         MINS = MINS,\n",
    "         TIME_STEPS = TIME_STEPS,\n",
    "         OUTPUT_SIZE = OUTPUT_SIZE\n",
    "        )\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data - Tomato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = './env_set/tom_env/'\n",
    "file_list = os.listdir(DIRECTORY)\n",
    "dataset_list = [file for file in file_list if file.endswith('.csv')]\n",
    "dataset_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PFS_0000008_tom_env.csv',\n",
       " 'PF_0000227_tom_env.csv',\n",
       " 'PF_0000304_tom_env.csv',\n",
       " 'PF_0001405_tom_env.csv',\n",
       " 'PF_0002525_tom_env.csv',\n",
       " 'PF_0002526_tom_env.csv',\n",
       " 'PF_0002527_tom_env.csv',\n",
       " 'PF_0002529_tom_env.csv',\n",
       " 'PF_0002533_tom_env.csv',\n",
       " 'Val_PF_0001396_tom_env.csv',\n",
       " 'Val_PF_0002528_tom_env.csv',\n",
       " 'Val_PF_0002531_tom_env.csv',\n",
       " 'Val_PF_0002532_tom_env.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5249.458333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data = []\n",
    "for FILENAME in dataset_list:\n",
    "    env_df = pd.read_csv(DIRECTORY + FILENAME, index_col=['MEAS_DATE']).dropna(how='all')\n",
    "    env_df = env_df[~(env_df == 0).all(axis=1)].interpolate().values\n",
    "    num_data.append(env_df.shape[0]/24)\n",
    "num_data = np.array(num_data)\n",
    "num_data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train_df = []\n",
    "temp_train_input = []\n",
    "temp_train_label = []\n",
    "temp_test_df = []\n",
    "temp_test_input = []\n",
    "temp_test_label = []\n",
    "for FILENAME in dataset_list:\n",
    "    env_df = pd.read_csv(DIRECTORY + FILENAME, index_col=['MEAS_DATE']).dropna(how='all')\n",
    "    env_df = env_df[~(env_df == 0).all(axis=1)].interpolate().values\n",
    "    np.random.seed(3101)\n",
    "    slicer = int((env_df.shape[0]-OUTPUT_SIZE - TIME_STEPS)/10)\n",
    "    test_index_start = (np.random.choice(10, 7, replace=False)*slicer).astype('int')\n",
    "    test_index_bound = np.concatenate([np.arange(_+TIME_STEPS, _+slicer-OUTPUT_SIZE) for _ in test_index_start])\n",
    "    test_index_start = np.concatenate([np.arange(_, _+slicer) for _ in test_index_start])\n",
    "    for INDEX in range(TIME_STEPS, env_df.shape[0]-OUTPUT_SIZE):\n",
    "        if INDEX in test_index_start:\n",
    "            if INDEX in test_index_bound:\n",
    "                temp_test_input.append(env_df[(INDEX-TIME_STEPS):INDEX, :])\n",
    "                temp_test_label.append(env_df[INDEX:(INDEX+OUTPUT_SIZE), :])\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            temp_train_input.append(env_df[(INDEX-TIME_STEPS):INDEX, :])\n",
    "            temp_train_label.append(env_df[INDEX:(INDEX+OUTPUT_SIZE), :])\n",
    "train_input = np.concatenate(temp_train_input)\n",
    "train_label = np.concatenate(temp_train_label)\n",
    "test_input = np.concatenate(temp_test_input)\n",
    "test_label = np.concatenate(temp_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = train_input.reshape(-1, TIME_STEPS, env_df.shape[-1])\n",
    "train_label = train_label.reshape(-1, OUTPUT_SIZE, env_df.shape[-1])\n",
    "test_input = test_input.reshape(-1, TIME_STEPS, env_df.shape[-1])\n",
    "test_label = test_label.reshape(-1, OUTPUT_SIZE, env_df.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37951, 24, 5)\n",
      "(37951, 24, 5)\n",
      "(83356, 24, 5)\n",
      "(83356, 24, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape)\n",
    "print(train_label.shape)\n",
    "print(test_input.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  42.4    37.35  100.   2999.    969.27]\n",
      "[  8.15 -20.92  27.87   1.67   0.  ]\n"
     ]
    }
   ],
   "source": [
    "print(MAXS)\n",
    "print(MINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = (train_input - MINS) / (MAXS - MINS)\n",
    "train_label = (train_label - MINS) / (MAXS - MINS)\n",
    "\n",
    "test_input = (test_input - MINS) / (MAXS - MINS)\n",
    "test_label = (test_label - MINS) / (MAXS - MINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37951, 24, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.40905109 1.00154453 1.         0.62308121 1.7228636 ]\n",
      "[1.40905109 1.00154453 1.         0.62308121 1.7228636 ]\n",
      "\n",
      "[1.52116788 1.01029689 1.         0.79417682 1.45896396]\n",
      "[1.52116788 1.01029689 1.         0.79417682 1.45896396]\n"
     ]
    }
   ],
   "source": [
    "print(train_input.max(axis=0).max(axis=0))\n",
    "print(train_label.max(axis=0).max(axis=0))\n",
    "print()\n",
    "print(test_input.max(axis=0).max(axis=0))\n",
    "print(test_label.max(axis=0).max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37951, 24, 5)\n",
      "(37951, 24, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83356, 24, 5)\n",
      "(83356, 24, 5)\n"
     ]
    }
   ],
   "source": [
    "print(test_input.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./env_set/val_tom_dataset.npz', 'wb')\n",
    "np.savez(f,\n",
    "         train_input = train_input,\n",
    "         train_label = train_label,\n",
    "         test_input = test_input,\n",
    "         test_label = test_label,\n",
    "         MAXS = MAXS,\n",
    "         MINS = MINS,\n",
    "         TIME_STEPS = TIME_STEPS,\n",
    "         OUTPUT_SIZE = OUTPUT_SIZE\n",
    "        )\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf20",
   "language": "python",
   "name": "tf20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
